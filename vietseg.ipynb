{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd03b7ace9d27dc1c502e3dae86da5e8433e0698b131550d06efd3a9ab1da013269",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip '/content/drive/MyDrive/mapplirary_vista_4labels.zip' -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/vietawake/RoadSeg\n",
    "# !mv -v RoadSeg/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vietnet import VietNet, CrossEntropyLoss2d\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import mobilenet_v2\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from load_dataset import ImageDataset\n",
    "from train import train_one_epoch, validate_model\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txtdata(path, file_name, label_name):\n",
    "  images_name = os.listdir(path)\n",
    "  for i in tqdm(range(len(images_name))):\n",
    "    name = images_name[i][:-4]\n",
    "    image = 'images/'+ name +'.jpg'\n",
    "    label = label_name + name + '.png'\n",
    "    sample_data = ', '.join([image, label])\n",
    "    images_name[i] = sample_data\n",
    "  return np.savetxt(file_name,images_name, delimiter='\\n', fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_txtdata(path='validation/images', file_name='val_list.txt',label_name='val_labels/')\n",
    "generate_txtdata(path='training/images', file_name='train_list.txt',label_name='train_labels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VietNet(num_classes= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "np.random.seed(50)\n",
    "torch.manual_seed(50)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(50)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "max_acc = 0\n",
    "patience = 10\n",
    "not_improved_count = 0\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    torchvision.transforms.Resize((384, 640),interpolation=Image.NEAREST),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = ImageDataset(root_dir='training/',\n",
    "                              txt_files='data/train_list.txt', \n",
    "                              img_size=(384, 640), \n",
    "                              transform=transform)\n",
    "\n",
    "val_dataset = ImageDataset(root_dir='validation/',\n",
    "                            txt_files='data/val_list.txt', \n",
    "                            img_size=(384, 640), \n",
    "                            transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=6)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss2d()\n",
    "optimizer = torch.optim.Adam(net.parameters(),5e-4,(0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, acc, train_jsc = train_one_epoch(net, criterion, optimizer, train_loader, device)\n",
    "    val_loss , val_acc, val_jsc = validate_model(net, criterion, val_loader, device)\n",
    "\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    print('Training acc: {:.4f}\\tTrain_jsc: {:.4f}\\tTraining Loss: {:.4f}'.format(acc,train_jsc,train_loss))\n",
    "    print('Valid acc: {:.4f}\\tValid_jsc: {:.4f}\\tValid Loss: {:.4f}'.format(val_acc,val_jsc, val_loss))\n",
    "\n",
    "    if val_acc > max_acc:\n",
    "        \n",
    "        torch.save(net.state_dict(), '/content/drive/MyDrive/checkpoints/RoadSeg_epoch_' + str(epoch) + '_acc_{0:.4f}'.format(val_acc)+'.pt')\n",
    "        max_acc = val_acc\n",
    "        not_improved_count = 0\n",
    "    else:\n",
    "        not_improved_count+=1\n",
    "    \n",
    "    if not_improved_count >=patience:\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 32, 192, 320]             864\n       BatchNorm2d-2         [-1, 32, 192, 320]              64\n             ReLU6-3         [-1, 32, 192, 320]               0\n            Conv2d-4         [-1, 32, 192, 320]             288\n       BatchNorm2d-5         [-1, 32, 192, 320]              64\n             ReLU6-6         [-1, 32, 192, 320]               0\n            Conv2d-7         [-1, 16, 192, 320]             512\n       BatchNorm2d-8         [-1, 16, 192, 320]              32\n  InvertedResidual-9         [-1, 16, 192, 320]               0\n           Conv2d-10         [-1, 96, 192, 320]           1,536\n      BatchNorm2d-11         [-1, 96, 192, 320]             192\n            ReLU6-12         [-1, 96, 192, 320]               0\n           Conv2d-13          [-1, 96, 96, 160]             864\n      BatchNorm2d-14          [-1, 96, 96, 160]             192\n            ReLU6-15          [-1, 96, 96, 160]               0\n           Conv2d-16          [-1, 24, 96, 160]           2,304\n      BatchNorm2d-17          [-1, 24, 96, 160]              48\n InvertedResidual-18          [-1, 24, 96, 160]               0\n           Conv2d-19         [-1, 144, 96, 160]           3,456\n      BatchNorm2d-20         [-1, 144, 96, 160]             288\n            ReLU6-21         [-1, 144, 96, 160]               0\n           Conv2d-22         [-1, 144, 96, 160]           1,296\n      BatchNorm2d-23         [-1, 144, 96, 160]             288\n            ReLU6-24         [-1, 144, 96, 160]               0\n           Conv2d-25          [-1, 24, 96, 160]           3,456\n      BatchNorm2d-26          [-1, 24, 96, 160]              48\n InvertedResidual-27          [-1, 24, 96, 160]               0\n           Conv2d-28         [-1, 144, 96, 160]           3,456\n      BatchNorm2d-29         [-1, 144, 96, 160]             288\n            ReLU6-30         [-1, 144, 96, 160]               0\n           Conv2d-31          [-1, 144, 48, 80]           1,296\n      BatchNorm2d-32          [-1, 144, 48, 80]             288\n            ReLU6-33          [-1, 144, 48, 80]               0\n           Conv2d-34           [-1, 32, 48, 80]           4,608\n      BatchNorm2d-35           [-1, 32, 48, 80]              64\n InvertedResidual-36           [-1, 32, 48, 80]               0\n           Conv2d-37          [-1, 192, 48, 80]           6,144\n      BatchNorm2d-38          [-1, 192, 48, 80]             384\n            ReLU6-39          [-1, 192, 48, 80]               0\n           Conv2d-40          [-1, 192, 48, 80]           1,728\n      BatchNorm2d-41          [-1, 192, 48, 80]             384\n            ReLU6-42          [-1, 192, 48, 80]               0\n           Conv2d-43           [-1, 32, 48, 80]           6,144\n      BatchNorm2d-44           [-1, 32, 48, 80]              64\n InvertedResidual-45           [-1, 32, 48, 80]               0\n           Conv2d-46          [-1, 192, 48, 80]           6,144\n      BatchNorm2d-47          [-1, 192, 48, 80]             384\n            ReLU6-48          [-1, 192, 48, 80]               0\n           Conv2d-49          [-1, 192, 48, 80]           1,728\n      BatchNorm2d-50          [-1, 192, 48, 80]             384\n            ReLU6-51          [-1, 192, 48, 80]               0\n           Conv2d-52           [-1, 32, 48, 80]           6,144\n      BatchNorm2d-53           [-1, 32, 48, 80]              64\n InvertedResidual-54           [-1, 32, 48, 80]               0\n           Conv2d-55          [-1, 192, 48, 80]           6,144\n      BatchNorm2d-56          [-1, 192, 48, 80]             384\n            ReLU6-57          [-1, 192, 48, 80]               0\n           Conv2d-58          [-1, 192, 24, 40]           1,728\n      BatchNorm2d-59          [-1, 192, 24, 40]             384\n            ReLU6-60          [-1, 192, 24, 40]               0\n           Conv2d-61           [-1, 64, 24, 40]          12,288\n      BatchNorm2d-62           [-1, 64, 24, 40]             128\n InvertedResidual-63           [-1, 64, 24, 40]               0\n           Conv2d-64          [-1, 384, 24, 40]          24,576\n      BatchNorm2d-65          [-1, 384, 24, 40]             768\n            ReLU6-66          [-1, 384, 24, 40]               0\n           Conv2d-67          [-1, 384, 24, 40]           3,456\n      BatchNorm2d-68          [-1, 384, 24, 40]             768\n            ReLU6-69          [-1, 384, 24, 40]               0\n           Conv2d-70           [-1, 64, 24, 40]          24,576\n      BatchNorm2d-71           [-1, 64, 24, 40]             128\n InvertedResidual-72           [-1, 64, 24, 40]               0\n           Conv2d-73          [-1, 384, 24, 40]          24,576\n      BatchNorm2d-74          [-1, 384, 24, 40]             768\n            ReLU6-75          [-1, 384, 24, 40]               0\n           Conv2d-76          [-1, 384, 24, 40]           3,456\n      BatchNorm2d-77          [-1, 384, 24, 40]             768\n            ReLU6-78          [-1, 384, 24, 40]               0\n           Conv2d-79           [-1, 64, 24, 40]          24,576\n      BatchNorm2d-80           [-1, 64, 24, 40]             128\n InvertedResidual-81           [-1, 64, 24, 40]               0\n           Conv2d-82          [-1, 384, 24, 40]          24,576\n      BatchNorm2d-83          [-1, 384, 24, 40]             768\n            ReLU6-84          [-1, 384, 24, 40]               0\n           Conv2d-85          [-1, 384, 24, 40]           3,456\n      BatchNorm2d-86          [-1, 384, 24, 40]             768\n            ReLU6-87          [-1, 384, 24, 40]               0\n           Conv2d-88           [-1, 64, 24, 40]          24,576\n      BatchNorm2d-89           [-1, 64, 24, 40]             128\n InvertedResidual-90           [-1, 64, 24, 40]               0\n           Conv2d-91          [-1, 384, 24, 40]          24,576\n      BatchNorm2d-92          [-1, 384, 24, 40]             768\n            ReLU6-93          [-1, 384, 24, 40]               0\n           Conv2d-94          [-1, 384, 24, 40]           3,456\n      BatchNorm2d-95          [-1, 384, 24, 40]             768\n            ReLU6-96          [-1, 384, 24, 40]               0\n           Conv2d-97           [-1, 96, 24, 40]          36,864\n      BatchNorm2d-98           [-1, 96, 24, 40]             192\n InvertedResidual-99           [-1, 96, 24, 40]               0\n          Conv2d-100          [-1, 576, 24, 40]          55,296\n     BatchNorm2d-101          [-1, 576, 24, 40]           1,152\n           ReLU6-102          [-1, 576, 24, 40]               0\n          Conv2d-103          [-1, 576, 24, 40]           5,184\n     BatchNorm2d-104          [-1, 576, 24, 40]           1,152\n           ReLU6-105          [-1, 576, 24, 40]               0\n          Conv2d-106           [-1, 96, 24, 40]          55,296\n     BatchNorm2d-107           [-1, 96, 24, 40]             192\nInvertedResidual-108           [-1, 96, 24, 40]               0\n          Conv2d-109          [-1, 576, 24, 40]          55,872\n     BatchNorm2d-110          [-1, 576, 24, 40]           1,152\n           ReLU6-111          [-1, 576, 24, 40]               0\n          Conv2d-112          [-1, 576, 24, 40]           5,760\n     BatchNorm2d-113          [-1, 576, 24, 40]           1,152\n           ReLU6-114          [-1, 576, 24, 40]               0\n          Conv2d-115          [-1, 160, 24, 40]          92,320\n     BatchNorm2d-116          [-1, 160, 24, 40]             320\n           ReLU6-117          [-1, 160, 24, 40]               0\n       Dropout2d-118          [-1, 160, 24, 40]               0\nconv_block_nested-119          [-1, 160, 24, 40]               0\n          Conv2d-120          [-1, 960, 24, 40]         154,560\n     BatchNorm2d-121          [-1, 960, 24, 40]           1,920\n           ReLU6-122          [-1, 960, 24, 40]               0\n          Conv2d-123          [-1, 960, 24, 40]           9,600\n     BatchNorm2d-124          [-1, 960, 24, 40]           1,920\n           ReLU6-125          [-1, 960, 24, 40]               0\n          Conv2d-126          [-1, 160, 24, 40]         153,760\n     BatchNorm2d-127          [-1, 160, 24, 40]             320\n           ReLU6-128          [-1, 160, 24, 40]               0\n       Dropout2d-129          [-1, 160, 24, 40]               0\nconv_block_nested-130          [-1, 160, 24, 40]               0\n          Conv2d-131          [-1, 256, 24, 40]          41,216\n          Conv2d-132          [-1, 256, 24, 40]          41,216\n     BatchNorm2d-133          [-1, 256, 24, 40]             512\n     BatchNorm2d-134          [-1, 256, 24, 40]             512\n           ReLU6-135          [-1, 256, 24, 40]               0\n           ReLU6-136          [-1, 256, 24, 40]               0\n          Conv2d-137          [-1, 256, 24, 40]         196,864\n          Conv2d-138          [-1, 256, 24, 40]         196,864\n     BatchNorm2d-139          [-1, 256, 24, 40]             512\n          Conv2d-140          [-1, 256, 24, 40]         196,864\n          Conv2d-141          [-1, 256, 24, 40]         196,864\n     BatchNorm2d-142          [-1, 256, 24, 40]             512\n       Dropout2d-143          [-1, 256, 24, 40]               0\nnon_bottleneck_1d-144          [-1, 256, 24, 40]               0\n          Conv2d-145          [-1, 256, 24, 40]         196,864\n          Conv2d-146          [-1, 256, 24, 40]         196,864\n     BatchNorm2d-147          [-1, 256, 24, 40]             512\n          Conv2d-148          [-1, 256, 24, 40]         196,864\n          Conv2d-149          [-1, 256, 24, 40]         196,864\n     BatchNorm2d-150          [-1, 256, 24, 40]             512\n       Dropout2d-151          [-1, 256, 24, 40]               0\nnon_bottleneck_1d-152          [-1, 256, 24, 40]               0\n          Conv2d-153          [-1, 256, 24, 40]         196,864\n          Conv2d-154          [-1, 256, 24, 40]         196,864\n     BatchNorm2d-155          [-1, 256, 24, 40]             512\n          Conv2d-156          [-1, 256, 24, 40]         196,864\n          Conv2d-157          [-1, 256, 24, 40]         196,864\n     BatchNorm2d-158          [-1, 256, 24, 40]             512\n       Dropout2d-159          [-1, 256, 24, 40]               0\nnon_bottleneck_1d-160          [-1, 256, 24, 40]               0\n          Conv2d-161          [-1, 256, 24, 40]         196,864\n          Conv2d-162          [-1, 256, 24, 40]         196,864\n     BatchNorm2d-163          [-1, 256, 24, 40]             512\n          Conv2d-164          [-1, 256, 24, 40]         196,864\n          Conv2d-165          [-1, 256, 24, 40]         196,864\n     BatchNorm2d-166          [-1, 256, 24, 40]             512\n       Dropout2d-167          [-1, 256, 24, 40]               0\nnon_bottleneck_1d-168          [-1, 256, 24, 40]               0\n ConvTranspose2d-169          [-1, 128, 48, 80]         295,040\n     BatchNorm2d-170          [-1, 128, 48, 80]             256\n  UpsamplerBlock-171          [-1, 128, 48, 80]               0\n          Conv2d-172          [-1, 128, 48, 80]          49,280\n          Conv2d-173          [-1, 128, 48, 80]          49,280\n     BatchNorm2d-174          [-1, 128, 48, 80]             256\n          Conv2d-175          [-1, 128, 48, 80]          49,280\n          Conv2d-176          [-1, 128, 48, 80]          49,280\n     BatchNorm2d-177          [-1, 128, 48, 80]             256\nnon_bottleneck_1d-178          [-1, 128, 48, 80]               0\n          Conv2d-179          [-1, 128, 48, 80]          49,280\n          Conv2d-180          [-1, 128, 48, 80]          49,280\n     BatchNorm2d-181          [-1, 128, 48, 80]             256\n          Conv2d-182          [-1, 128, 48, 80]          49,280\n          Conv2d-183          [-1, 128, 48, 80]          49,280\n     BatchNorm2d-184          [-1, 128, 48, 80]             256\nnon_bottleneck_1d-185          [-1, 128, 48, 80]               0\n ConvTranspose2d-186          [-1, 64, 96, 160]          73,792\n     BatchNorm2d-187          [-1, 64, 96, 160]             128\n  UpsamplerBlock-188          [-1, 64, 96, 160]               0\n          Conv2d-189          [-1, 64, 96, 160]          12,352\n          Conv2d-190          [-1, 64, 96, 160]          12,352\n     BatchNorm2d-191          [-1, 64, 96, 160]             128\n          Conv2d-192          [-1, 64, 96, 160]          12,352\n          Conv2d-193          [-1, 64, 96, 160]          12,352\n     BatchNorm2d-194          [-1, 64, 96, 160]             128\nnon_bottleneck_1d-195          [-1, 64, 96, 160]               0\n          Conv2d-196          [-1, 64, 96, 160]          12,352\n          Conv2d-197          [-1, 64, 96, 160]          12,352\n     BatchNorm2d-198          [-1, 64, 96, 160]             128\n          Conv2d-199          [-1, 64, 96, 160]          12,352\n          Conv2d-200          [-1, 64, 96, 160]          12,352\n     BatchNorm2d-201          [-1, 64, 96, 160]             128\nnon_bottleneck_1d-202          [-1, 64, 96, 160]               0\n ConvTranspose2d-203         [-1, 16, 192, 320]           9,232\n     BatchNorm2d-204         [-1, 16, 192, 320]              32\n  UpsamplerBlock-205         [-1, 16, 192, 320]               0\n          Conv2d-206         [-1, 16, 192, 320]             784\n          Conv2d-207         [-1, 16, 192, 320]             784\n     BatchNorm2d-208         [-1, 16, 192, 320]              32\n          Conv2d-209         [-1, 16, 192, 320]             784\n          Conv2d-210         [-1, 16, 192, 320]             784\n     BatchNorm2d-211         [-1, 16, 192, 320]              32\nnon_bottleneck_1d-212         [-1, 16, 192, 320]               0\n          Conv2d-213         [-1, 16, 192, 320]             784\n          Conv2d-214         [-1, 16, 192, 320]             784\n     BatchNorm2d-215         [-1, 16, 192, 320]              32\n          Conv2d-216         [-1, 16, 192, 320]             784\n          Conv2d-217         [-1, 16, 192, 320]             784\n     BatchNorm2d-218         [-1, 16, 192, 320]              32\nnon_bottleneck_1d-219         [-1, 16, 192, 320]               0\n ConvTranspose2d-220          [-1, 4, 384, 640]             260\n================================================================\nTotal params: 5,020,020\nTrainable params: 5,020,020\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 2.81\nForward/backward pass size (MB): 1139.06\nParams size (MB): 19.15\nEstimated Total Size (MB): 1161.02\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (3, 384, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}